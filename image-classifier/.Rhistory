12+4
testing
5%2
7/2
1234/4324
43515/341/2341/42432/
4
43124/241/2341/2341/243/134/1/341
true
7/3
7/3
2+1
7/3
2+1
7/3
7/22
22/7
22/7
2+1
22/7
"string text"
source('D:/R workspace/practice.R', echo=TRUE)
print("sup bruh")
source('D:/R workspace/practice.R', echo=TRUE)
y+1
y =3
y+1
number+2
number <- 123
number+2
source('D:/R workspace/practice.R', echo=TRUE)
letter <= 'l'
source('D:/R workspace/practice.R', echo=TRUE)
source('D:/R workspace/practice.R', echo=TRUE)
source('D:/R workspace/practice.R', echo=TRUE)
source('D:/R workspace/practice.R', echo=TRUE)
source('D:/R workspace/practice.R', echo=TRUE)
source('D:/R workspace/practice.R', echo=TRUE)
source('D:/R workspace/practice.R', echo=TRUE)
source('D:/R workspace/practice.R', echo=TRUE)
source('D:/R workspace/practice.R', echo=TRUE)
print(word)
source('D:/R workspace/practice.R', echo=TRUE)
source('D:/GithubRepos/exercises-leverage180/ch5-r-intro/exercise-1/exercise.R', echo=TRUE)
source('D:/GithubRepos/exercises-leverage180/ch5-r-intro/exercise-1/exercise.R', echo=TRUE)
source('D:/GithubRepos/lab-exercises/week-2/exercise.R', echo=TRUE)
my_num <- 6
source('D:/GithubRepos/lab-exercises/week-2/exercise.R', echo=TRUE)
install.packages("stringr")
source('D:/GithubRepos/lab-exercises/week-2/exercise.R', echo=TRUE)
new_vector <- c(1, 2)
typrof(new_vector)
new_vector <- c(1, 2)
typeof(new_vector)
print(new_vector)
typeof(new_vector)
print(new_vector)
source('D:/GithubRepos/lab-exercises/week-2/exercise.R', echo=TRUE)
# Pass two vectors of different length to your `CompareLength` function
CompareLength(new_vector, c(5,5))
CompareLength <- function(v1, v2) {
return ("The difference in lengths is ") abs(v1-v2)
}
# Pass two vectors of different length to your `CompareLength` function
CompareLength(new_vector, c(5,5))
CompareLength <- function(new_vector, other_vector) {
return ("The difference in lengths is ") abs(v1-v2)
}
CompareLength <- function(new_vector, other_vector) {
return ("The difference in lengths is ")
abs(v1-v2)
}
print(CompareLength)
print(CompareLength)
print(CompareLength)
CompareLength <- function(new_vector, other_vector) {
return ("The difference in lengths is " abs(new_vector, other_vector))
}
print(CompareLength)
CompareLength <- function(new_vector, other_vector) {
return ("The difference in lengths is " abs(new_vector - other_vector))
}
CompareLength <- function(new_vector, other_vector) {
x <- abs(new_vector - other_vector)
return x
}
CompareLength <- function(new_vector, other_vector) {
x <- abs(2 - 5)
return x
}
CompareLength <- function(new_vector, other_vector) {
x <- abs(2 - 5)
return x
}
print(CompareLength)
CompareLength <- function(new_vector, other_vector) {
x <- abs(2 - 5)
return x
}
print(CompareLength)
CompareLength <- function(new_vector, other_vector) {
x <- abs(2 - 5)
return x
}
# run ?sum to get more info
?sum
vector_sum <- sum(my_vector)
source('D:/GithubRepos/lab-exercises/week-2/exercise.R', echo=TRUE)
source('D:/GithubRepos/lab-exercises/week-2/exercise.R', echo=TRUE)
source('D:/GithubRepos/lab-exercises/week-2/exercise.R', echo=TRUE)
source('D:/GithubRepos/lab-exercises/week-2/exercise.R', echo=TRUE)
?str_length
??str_length
?StrLengthh
?StrLength
source('D:/GithubRepos/lab-exercises/week-2/exercise.R', echo=TRUE)
source('D:/GithubRepos/lab-exercises/week-2/exercise.R', echo=TRUE)
source('D:/GithubRepos/lab-exercises/week-2/exercise.R', echo=TRUE)
source('D:/GithubRepos/lab-exercises/week-2/exercise.R', echo=TRUE)
source('D:/GithubRepos/lab-exercises/week-2/exercise.R', echo=TRUE)
source('D:/GithubRepos/lab-exercises/week-2/exercise.R', echo=TRUE)
source('D:/GithubRepos/lab-exercises/week-2/exercise.R', echo=TRUE)
# Use the `stat_count` to apply the statistical transformation "count" to the
# diamonds by cut. You do not need a separate geometry layer!
ggplot(data = diamonds) +
geom_bar(aes(x = cut), stat_count)
source('D:/GithubRepos/exercises-leverage180/ch13-ggplot2/exercise-2/exercise.R', echo=TRUE)
source('D:/GithubRepos/exercises-leverage180/ch13-ggplot2/exercise-2/exercise.R', echo=TRUE)
animated_wealth_v_emissions
source('D:/GithubRepos/a6-data-visualization-leverage180/A6script.R', echo=TRUE)
getwd()
install.packages("shiny")
library(shiny)
my_ui <- fluidPage(
h1("Hello Shiny"),
textInput('user_name', label = "What is your name?")
)
shineyApp(ui = my_ui, server = myserver)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
?sliderInput
?s;oderImpit
?sliderInput()
?slectInput
?selectInput
shiny::runApp('D:/GithubRepos/a8-data-app-leverage180')
?selectInput
runApp('D:/GithubRepos/a8-data-app-leverage180')
runApp('D:/GithubRepos/a8-data-app-leverage180')
runApp('D:/GithubRepos/a8-data-app-leverage180')
runApp('D:/GithubRepos/a8-data-app-leverage180')
library(ggplot2)
runApp('D:/GithubRepos/a8-data-app-leverage180')
runApp('D:/GithubRepos/a8-data-app-leverage180')
runApp('D:/GithubRepos/a8-data-app-leverage180')
runApp('D:/GithubRepos/a8-data-app-leverage180')
runApp('D:/GithubRepos/a8-data-app-leverage180')
runApp('D:/GithubRepos/a8-data-app-leverage180')
runApp('D:/GithubRepos/a8-data-app-leverage180')
runApp('D:/GithubRepos/a8-data-app-leverage180')
View(eviction_data_county)
View(eviction_data_county)
runApp('D:/GithubRepos/a8-data-app-leverage180')
runApp('D:/GithubRepos/a8-data-app-leverage180')
runApp('D:/GithubRepos/a8-data-app-leverage180')
## Uncomment this to install packages
install.packages('rvest')
# Load in 'rvest' package
library('rvest')
'Specify the URL endpoint we are using'
url <- 'http://www.imdb.com/search/title?count=100&release_date=2016,2016&title_type=feature'
webpage <- read_html(url)
View(webpage)
rank_data_html <- html_nodes(webpage,'.text-primary')
rank_data <- html_text(rank_data_html)
head(rank_data)
rank_data<-as.numeric(rank_data)
head(rank_data)
#Using CSS selectors to scrape the title section
title_data_html <- html_nodes(webpage, ".lister-item-header a")
#html to text
title_data <- html_text(title_data_html)
#look at data
head(title_data)
#Using CSS selectors to scrape the description section
description_data_html <- html_nodes(webpage, ".ratings-bar+ .text-muted")
#Converting the description data to text
description_data <- html_text(description_data_html)
#look at data
head(description_data)
install.packages('syuzhet')
library(syuzhet)
student_sentiments <- data.frame(get_sentiment(student_sentences, method = "syuzhet"))
# Create a vector of emotional sentences.
# Add some happy ones, angry ones - you name it!
student_sentences <- c('I really like the pie you gave me this morning.',
'Your shoes suck and are just plain ugly.',
'I\'d really truly love going out in this weather!'
)
student_sentiments <- data.frame(get_sentiment(student_sentences, method = "syuzhet"))
# install.packages('dplyr')
# install.packages('stringr')
install.packages('tidytext')
# install.packages('dplyr')
install.packages('stringr')
library(dplyr)
library(stringr)
library(tidytext)
library(tidyr)
library(ggplot2)
##### LEXICONS #####
# Use the get_sentiments() function to get your dictionary of positive
# and negative words. Use the lexicon which categorizes words into
# positive and negative.
bing_sentiments <- get_sentiments("bing")
books <- read.csv("./data/austen_books.csv", stringsAsFactors = FALSE)
books <- read.csv("../data/austen_books.csv", stringsAsFactors = FALSE)
getwd()
setwd("../GithubRepos/mini-demos/sentiment_analysis")
setwd("../GithubRepos/mini-demos/sentiment_analysis")
setwd("../../GithubRepos/mini-demos/sentiment_analysis")
books <- read.csv("./data/austen_books.csv", stringsAsFactors = FALSE)
# Map each word in the 'books' dataset to its dictionary-prescribed sentiment.
jane_austen_sentiment <- books %>%
inner_join(bing_sentiments, by = "word")
# Instead of having each individual word, count the number of positive/negative
# words in each chapter.
jane_austen_sentiment <- jane_austen_sentiment %>%
count(book, chapter, sentiment)
# A chapter's overarching feeling will be calculated by the number of positive
# words minus the number of negative words. Create a new column called
# 'sentiment' with this value.
jane_austen_sentiment <- jane_austen_sentiment %>%
spread(sentiment, n, fill = 0)
View(jane_austen_sentiment)
# A chapter's overarching feeling will be calculated by the number of positive
# words minus the number of negative words. Create a new column called
# 'sentiment' with this value.
jane_austen_sentiment <- jane_austen_sentiment %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
# A chapter's overarching feeling will be calculated by the number of positive
# words minus the number of negative words. Create a new column called
# 'sentiment' with this value.
jane_austen_sentiment <- jane_austen_sentiment %>%
spread(sentiment, n, fill = 0) %>%
mutate("sentiment" = positive - negative)
# A chapter's overarching feeling will be calculated by the number of positive
# words minus the number of negative words. Create a new column called
# 'sentiment' with this value.
jane_austen_sentiment <- jane_austen_sentiment %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment_ = positive - negative)
#load library
library(class) #Has the knn function
#load library
library(class) #Has the knn function
#loading data
data("iris")
#Set the seed for reproducibility
set.seed(4948493)
#Sample the Iris data set (70% train, 30% test)
ir_sample <- sample(1:nrow(iris),size=nrow(iris)*.7)
ir_train <- iris[ir_sample,] #Select the 70% of rows
ir_test <- iris[-ir_sample,] #Select the 30% of rows
#Find Accuracy of Prediction
accuracy = function(actual, predicted) {
mean(actual == predicted)
}
#test for single k
pred <- knn(train = scale(ir_train[,-5]),
test = scale(ir_test[,-5]),
cl = ir_train$Species,
k = 40)
accuracy(ir_test$Species, pred)
#LOOP FOR MULTIPLE K's
k_to_try = 1:100
acc_k = rep(x = 0, times = length(k_to_try))
for(i in seq_along(k_to_try)) {
pred <- knn(train = scale(ir_train[,-5]),
test = scale(ir_test[,-5]),
cl = ir_train$Species,
k = k_to_try[i])
acc_k[i] <- accuracy(ir_test$Species, pred)
}
plot(acc_k, type = "b", col = "dodgerblue", cex = 1, pch = 20,
xlab = "k, number of neighbors", ylab = "classification accuracy",
main = "Accuracy vs Neighbors")
# First, install the keras R package from GitHub as follows:
devtools::install_github("rstudio/keras")
# Load in a pretrained model: Using Inception V3 with ImageNet weights
model <- application_inception_v3(weights = "imagenet")
# Load in image from `imgs` directory. Images include that of an elephant, hamster, apples and oranges
# Feel free to add your own images to the directory to test the model
img_path <- "./imgs/elephant.jpg"
img <- image_load(img_path, target_size = c(299, 299))
getwd()
setwd(../image-classifier)
setwd("../image-classifier")
img <- image_load(img_path, target_size = c(299, 299))
getwd()
# Load in image from `imgs` directory. Images include that of an elephant, hamster, apples and oranges
# Feel free to add your own images to the directory to test the model
img_path <- "./imgs/elephant.jpg"
img <- image_load(img_path, target_size = c(299, 299))
# The Keras R interface uses the TensorFlow backend engine by default.
# To install both the core Keras library as well as the TensorFlow backend use the install_keras() function:
library(keras)
install_keras()
# First, install the keras R package from GitHub as follows:
devtools::install_github("rstudio/keras")
# First, install the keras R package from GitHub as follows:
devtools::install_github("rstudio/keras")
# The Keras R interface uses the TensorFlow backend engine by default.
# To install both the core Keras library as well as the TensorFlow backend use the install_keras() function:
library(keras)
# The Keras R interface uses the TensorFlow backend engine by default.
# To install both the core Keras library as well as the TensorFlow backend use the install_keras() function:
library("keras")
install_keras()
install.packages('recommenderlab')
install.packages('data.table')
install.packages('reshape2')
library(recommenderlab)
library(data.table)
library(reshape2)
library(ggplot2)
# Read in the movies and ratings data sets
movies <- read.csv("data/movies.csv", stringsAsFactors = FALSE)
ratings <- read.csv("data/ratings.csv", stringsAsFactors = FALSE)
